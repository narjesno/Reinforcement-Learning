{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cv5yS4nOzETU"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!pip install import-ipynb\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0z4ehxH3zN4W"
   },
   "outputs": [],
   "source": [
    "%cd drive\n",
    "%cd 'My Drive'\n",
    "%cd 'RL'\n",
    "%cd 'Homework'\n",
    "%cd 'Homework 4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8371,
     "status": "ok",
     "timestamp": 1609763111023,
     "user": {
      "displayName": "Narjes Noorzad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj7tkVNhkAPpQLlGPleUdGAeLotodizEcuFCkFIkA=s64",
      "userId": "16921968874120068723"
     },
     "user_tz": -210
    },
    "id": "MaRbn7L5z0rI",
    "outputId": "992c3978-a4ad-46ec-e012-99393a2b16b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Environment.ipynb\n",
      "Collecting colorama\n",
      "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
      "Installing collected packages: colorama\n",
      "Successfully installed colorama-0.4.4\n",
      "importing Jupyter notebook from Modified_Environment.ipynb\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "'''Needed Libraries and Environment'''\n",
    "import Environment\n",
    "import Modified_Environment\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import itertools\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "'''Constants Defined'''\n",
    "STATE = 0\n",
    "ACTION = 1\n",
    "REWARD = 2\n",
    "MAX_T = 10000\n",
    "TOTAL_EPISODES = 2000\n",
    "gamma = 0.8\n",
    "ALPHA = 0.2\n",
    "MIN = 0.001\n",
    "DECAY_FACTOR = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 2708,
     "status": "ok",
     "timestamp": 1609766245997,
     "user": {
      "displayName": "Narjes Noorzad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj7tkVNhkAPpQLlGPleUdGAeLotodizEcuFCkFIkA=s64",
      "userId": "16921968874120068723"
     },
     "user_tz": -210
    },
    "id": "eLjNXzQysKw1"
   },
   "outputs": [],
   "source": [
    "class OffPolicyMCAgent():\n",
    "  \n",
    "    def __init__(self, env, behaviour_policy, gamma):\n",
    "\n",
    "      self.env = env\n",
    "      self.Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "      self.C = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "      self.actions = env.action_space.n\n",
    "      self.behaviour_policy = behaviour_policy\n",
    "      self.gamma = gamma\n",
    "      self.G = 0.0\n",
    "      self.W = 1.0\n",
    "      self.Off_MC_episode_scores = []\n",
    "      self.returns_sum = defaultdict(float)\n",
    "      self.returns_count = defaultdict(float)\n",
    "      self.episode_information = []\n",
    "      self.states_in_episode = []\n",
    "\n",
    "    def target_policy(self, state):\n",
    "        A = np.zeros_like(self.Q[state], dtype=float)\n",
    "        best_action = np.argmax(self.Q[state])\n",
    "        A[best_action] = 1.0\n",
    "        return A\n",
    "\n",
    "\n",
    "    def reach_island(self):\n",
    "        #epsilon = 1 #<-- uncomment if you want to use decaying epsilon \n",
    "        #epsilon = 0.3 #<-- uncomment if you want to use constant epsilon \n",
    "        for episode in range(1, TOTAL_EPISODES + 1):\n",
    "            episode_score = 0\n",
    "            if episode % 4 == 0:\n",
    "                print(\"\\rEpisode {}/{}.\".format(episode, TOTAL_EPISODES), end=\"\")\n",
    "                sys.stdout.flush()\n",
    "                epsilon = max(epsilon * DECAY_FACTOR, MIN) #<-- uncomment if you want to use decaying epsilon \n",
    "            done = False\n",
    "            state = self.env.reset()\n",
    "            for t in itertools.count():\n",
    "                probs = self.behaviour_policy(self.Q, state, epsilon)\n",
    "                action = np.random.choice(np.arange(len(probs)), p = probs)\n",
    "                state_prime, reward, done, _ = self.env.step(action)\n",
    "                episode_score += reward\n",
    "                self.episode_information.append((state, action, reward))\n",
    "                self.states_in_episode.append(state)\n",
    "                if done or t > MAX_T :\n",
    "                  break\n",
    "                state = state_prime\n",
    "            self.off_policy_returns(epsilon)\n",
    "            self.Off_MC_episode_scores.insert(0, episode_score)\n",
    "\n",
    "\n",
    "    def off_policy_returns(self, epsilon):\n",
    "        self.G, self.W = 0, 1\n",
    "        for ep in range(len(self.episode_information))[::-1]:\n",
    "            state, action, reward = self.episode_information[ep]\n",
    "            self.G = self.gamma*self.G + reward\n",
    "            self.C[state][action] += self.W\n",
    "            self.Q[state][action] += (self.W/self.C[state][action]) * (self.G - self.Q[state][action])\n",
    "            if action != np.argmax(self.target_policy(state)):\n",
    "                break\n",
    "            self.W = self.W * (self.target_policy(state)[action]/self.behaviour_policy(self.Q, state, epsilon)[action])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1684,
     "status": "ok",
     "timestamp": 1609763115080,
     "user": {
      "displayName": "Narjes Noorzad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj7tkVNhkAPpQLlGPleUdGAeLotodizEcuFCkFIkA=s64",
      "userId": "16921968874120068723"
     },
     "user_tz": -210
    },
    "id": "1x6gkioEpeyQ"
   },
   "outputs": [],
   "source": [
    "def create_behaviour_policy(nA):\n",
    "    def policy_fn(Q, observation, epsilon):\n",
    "        A = np.ones(nA, dtype=float) * epsilon / nA\n",
    "        best_action = np.argmax(Q[observation])\n",
    "        A[best_action] += (1.0 - epsilon)\n",
    "        return A\n",
    "    return policy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 373447,
     "status": "ok",
     "timestamp": 1609766620295,
     "user": {
      "displayName": "Narjes Noorzad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj7tkVNhkAPpQLlGPleUdGAeLotodizEcuFCkFIkA=s64",
      "userId": "16921968874120068723"
     },
     "user_tz": -210
    },
    "id": "MRhXEK40ph_H",
    "outputId": "11559e19-b339-468b-e84e-f32c341dcf58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2000/2000."
     ]
    }
   ],
   "source": [
    "# env =  Environment.GridworldEnv() #<--uncomment for normal environment\n",
    "#env =  Modified_Environment.GridworldEnv() # <--uncomment for modified environment (bonus part)\n",
    "behaviour_policy = create_behaviour_policy(env.action_space.n)\n",
    "agent = OffPolicyMCAgent(env, behaviour_policy, gamma)\n",
    "agent.reach_island()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ftIYvUHrSby"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(TOTAL_EPISODES), agent.Off_MC_episode_scores, color = '#633974', label = '$\\epsilon$ = from $1$ to $0.01$')\n",
    "plt.xlabel('episodes ->')\n",
    "plt.ylabel('epsiode score ->')\n",
    "plt.title('Off-policy Monte Carlo')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S6qHAvDFsJFA"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "window_size = 50\n",
    "smoothed_score = pd.Series(agent.Off_MC_episode_scores).rolling(window_size , min_periods = window_size).mean()\n",
    "plt.plot(smoothed_score, color = '#633974', label = '$\\epsilon$ = from $1$ to $0.01$')\n",
    "#plt.annotate(smoothed_score.iloc[-1], xy=(2000, smoothed_score.iloc[-1]), xytext=(2000, smoothed_score.iloc[-1]), color = '#633974',) # <--uncomment for modified environment (bonus part)\n",
    "plt.xlabel(\"epsiode ->\")\n",
    "plt.ylabel(\"epsiode score (smoothed) -> \")\n",
    "plt.title('Off-policy Monte Carlo')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 1267,
     "status": "ok",
     "timestamp": 1609766684989,
     "user": {
      "displayName": "Narjes Noorzad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj7tkVNhkAPpQLlGPleUdGAeLotodizEcuFCkFIkA=s64",
      "userId": "16921968874120068723"
     },
     "user_tz": -210
    },
    "id": "u6qW9rFhqT00"
   },
   "outputs": [],
   "source": [
    "#i wrote my reward data into a .txt file to use it later.\n",
    "\n",
    "# with open('Off_MC_bonus_scores', 'wb') as fp:\n",
    "    # pickle.dump(agent.Off_MC_episode_scores, fp)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNDZLir2L8S5+kzWT366rSz",
   "collapsed_sections": [],
   "name": "Off-policy_MonteCarlo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
