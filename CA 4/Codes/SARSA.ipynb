{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SARSA.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPnITYeKXIEg9z/PPOdnHjs"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"Cv5yS4nOzETU"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')\r\n","!pip install import-ipynb\r\n","import import_ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0z4ehxH3zN4W"},"source":["%cd drive\r\n","%cd 'My Drive'\r\n","%cd 'RL'\r\n","%cd 'Homework'\r\n","%cd 'Homework 4'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MaRbn7L5z0rI"},"source":["'''Needed Libraries and Environment'''\r\n","import Environment\r\n","import Modified_Environment\r\n","import matplotlib.pyplot as plt\r\n","import numpy as np\r\n","import math\r\n","import random\r\n","from collections import defaultdict\r\n","import sys\r\n","import itertools\r\n","import matplotlib\r\n","import pandas as pd\r\n","import pickle\r\n","\r\n","'''Constants Defined'''\r\n","PROBABILITY = 0\r\n","STATE = 1\r\n","ACTION = 2\r\n","REWARD = 3\r\n","MAX_T = 10000\r\n","TOTAL_EPISODES = 2000\r\n","gamma = 0.9\r\n","ALPHA = 0.2\r\n","MIN = 0.1\r\n","DECAY_FACTOR = 0.99"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"StR7y4zseEJA"},"source":["class SarsaAgent():\r\n","  \r\n","    def __init__(self, env, gamma):\r\n","      self.env = env\r\n","      self.Q = defaultdict(lambda: np.zeros(env.action_space.n))\r\n","      self.actions = env.action_space.n\r\n","      self.gamma = gamma\r\n","      self.sarsa_episode_scores = []\r\n","\r\n","    def epsilon_greedy_policy(self, state, epsilon):\r\n","        epsilon_policy = np.ones(self.actions, dtype=float) * epsilon / self.actions\r\n","        best_action = np.argmax(self.Q[state])\r\n","        epsilon_policy[best_action] += (1.0 - epsilon)\r\n","        return epsilon_policy\r\n","\r\n","    def reach_island(self):\r\n","        #epsilon = 1 #<-- uncomment if you want to use decaying epsilon \r\n","        #epsilon = 0.3 #<-- uncomment if you want to use constant epsilon\r\n","        for episode in range(1, TOTAL_EPISODES + 1):\r\n","            episode_score = 0\r\n","            if episode % 2 == 0:\r\n","              #epsilon = max(epsilon * DECAY_FACTOR, MIN) #<-- uncomment if you want to use decaying epsilon\r\n","              print(\"\\rEpisode {}/{}.\".format(episode, TOTAL_EPISODES), end=\"\")\r\n","              sys.stdout.flush()\r\n","            state = self.env.reset()\r\n","            done = False\r\n","            probs = self.epsilon_greedy_policy(state, epsilon)\r\n","            action = np.random.choice(np.arange(len(probs)), p = probs)\r\n","            for t in itertools.count():\r\n","                next_state, reward, done, _ = self.env.step(action)\r\n","                next_probs = self.epsilon_greedy_policy(next_state, epsilon)\r\n","                next_action = np.random.choice(np.arange(len(next_probs)), p = next_probs)\r\n","                episode_score += reward\r\n","                information, next_information = [probs, state, action, reward], [next_probs, next_state, next_action]\r\n","                self.sarsa_returns(information, next_information)\r\n","                if done or t < MAX_T : break\r\n","                state, action = next_state, next_action\r\n","            self.sarsa_episode_scores.append(episode_score)\r\n","\r\n","    def sarsa_returns(self, info, next_info):\r\n","        target = info[REWARD] + self.gamma * self.Q[next_info[STATE]][next_info[ACTION]]\r\n","        self.Q[info[STATE]][info[ACTION]] += ALPHA * (target - self.Q[info[STATE]][info[ACTION]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IbLlNOFiIAd1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609759518979,"user_tz":-210,"elapsed":10247,"user":{"displayName":"Narjes Noorzad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7tkVNhkAPpQLlGPleUdGAeLotodizEcuFCkFIkA=s64","userId":"16921968874120068723"}},"outputId":"20ef8bad-fbef-4275-b76d-495945bc119e"},"source":["# env =  Environment.GridworldEnv() #<--uncomment for normal environment\r\n","# env =  Modified_Environment.GridworldEnv() # <--uncomment for modified environment (bonus part)\r\n","agent = SarsaAgent(env, gamma)\r\n","agent.reach_island()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Episode 2000/2000."],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e6GgBytPca71"},"source":["plt.figure(figsize=(12, 6))\r\n","plt.plot(range(TOTAL_EPISODES), agent.sarsa_episode_scores, color = '#633974', label = '$\\epsilon$ = from $1$ to $0.1$')\r\n","plt.xlabel('Episodes ->')\r\n","plt.ylabel('Score ->')\r\n","plt.title('SARSA')\r\n","plt.legend()\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9NuCZyGLcpOA"},"source":["fig = plt.figure(figsize=(12 ,6))\r\n","window = 50\r\n","smoothed_score = pd.Series(agent.sarsa_episode_scores).rolling(window , min_periods = window).mean()\r\n","plt.plot(smoothed_score, color = '#633974', label = '$\\epsilon$ = from $1$ to $0.1$')\r\n","plt.xlabel(\"epsiode ->\")\r\n","plt.ylabel(\"epsiode score (smoothed) -> \")\r\n","#plt.annotate(smoothed_score.iloc[-1], xy=(2000, -14), xytext=(2000, -14), color = '#633974',) # <--uncomment for modified environment (bonus part)\r\n","plt.title('SARSA')\r\n","plt.legend()\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bS0ds8OwSOkg"},"source":["#i wrote my reward data into a file to use it later\r\n","\r\n","# with open('sarsa_episode_scores', 'wb') as fp:\r\n","#     pickle.dump(agent.sarsa_episode_scores, fp)"],"execution_count":null,"outputs":[]}]}