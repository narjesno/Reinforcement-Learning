{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 77509,
     "status": "ok",
     "timestamp": 1609759340262,
     "user": {
      "displayName": "Narjes Noorzad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj7tkVNhkAPpQLlGPleUdGAeLotodizEcuFCkFIkA=s64",
      "userId": "16921968874120068723"
     },
     "user_tz": -210
    },
    "id": "Cv5yS4nOzETU",
    "outputId": "bda2bd11-f5d7-41ad-e748-3f56d1f24961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Collecting import-ipynb\n",
      "  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n",
      "Building wheels for collected packages: import-ipynb\n",
      "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp36-none-any.whl size=2976 sha256=021c0b8aeaf12fe44fdf98573942ea6c72f329b22be9687986da7867378aef03\n",
      "  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n",
      "Successfully built import-ipynb\n",
      "Installing collected packages: import-ipynb\n",
      "Successfully installed import-ipynb-0.1.3\n",
      "Collecting colorama\n",
      "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
      "Installing collected packages: colorama\n",
      "Successfully installed colorama-0.4.4\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!pip install import-ipynb\n",
    "import import_ipynb\n",
    "!pip install colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1099,
     "status": "ok",
     "timestamp": 1609759352763,
     "user": {
      "displayName": "Narjes Noorzad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj7tkVNhkAPpQLlGPleUdGAeLotodizEcuFCkFIkA=s64",
      "userId": "16921968874120068723"
     },
     "user_tz": -210
    },
    "id": "0z4ehxH3zN4W",
    "outputId": "99750fd9-e29d-4122-d130-faf629cdce04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive\n",
      "/content/drive/My Drive\n",
      "/content/drive/My Drive/RL\n",
      "/content/drive/My Drive/RL/Homework\n",
      "/content/drive/My Drive/RL/Homework/Homework 4\n"
     ]
    }
   ],
   "source": [
    "%cd drive\n",
    "%cd 'My Drive'\n",
    "%cd 'RL'\n",
    "%cd 'Homework'\n",
    "%cd 'Homework 4'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 1291,
     "status": "ok",
     "timestamp": 1609764194077,
     "user": {
      "displayName": "Narjes Noorzad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj7tkVNhkAPpQLlGPleUdGAeLotodizEcuFCkFIkA=s64",
      "userId": "16921968874120068723"
     },
     "user_tz": -210
    },
    "id": "MaRbn7L5z0rI"
   },
   "outputs": [],
   "source": [
    "'''Needed Libraries and Environment'''\n",
    "import Environment\n",
    "import Modified_Environment\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import itertools\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "'''Constants Defined'''\n",
    "STATE = 0\n",
    "ACTION = 1\n",
    "REWARD = 2\n",
    "MAX_T = 100000\n",
    "TOTAL_EPISODES = 2000\n",
    "gamma = 0.9\n",
    "MIN = 0.1\n",
    "DECAY_FACTOR = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 1054,
     "status": "ok",
     "timestamp": 1609768226424,
     "user": {
      "displayName": "Narjes Noorzad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj7tkVNhkAPpQLlGPleUdGAeLotodizEcuFCkFIkA=s64",
      "userId": "16921968874120068723"
     },
     "user_tz": -210
    },
    "id": "StR7y4zseEJA"
   },
   "outputs": [],
   "source": [
    "class OnPolicyMCAgent():\n",
    "  \n",
    "    def __init__(self, env, gamma):\n",
    "      self.env = env\n",
    "      self.Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "      self.actions = env.action_space.n\n",
    "      self.gamma = gamma\n",
    "      self.returns_sum = defaultdict(float)\n",
    "      self.returns_count = defaultdict(float)\n",
    "      self.episode_information = []\n",
    "      self.MC_episode_scores = []\n",
    "\n",
    "\n",
    "    def epsilon_greedy_policy(self, state, epsilon):\n",
    "        epsilon_policy = np.ones(self.actions, dtype=float) * epsilon / self.actions\n",
    "        best_action = np.argmax(self.Q[state])\n",
    "        epsilon_policy[best_action] += (1.0 - epsilon)\n",
    "        return epsilon_policy\n",
    "\n",
    "\n",
    "    def reach_island(self):\n",
    "        #epsilon = 0.5 #<-- uncomment if you want to use decaying epsilon \n",
    "        #epsilon = 0.3 #<-- uncomment if you want to use constant epsilon\n",
    "        for episode in range(1, TOTAL_EPISODES + 1):\n",
    "            episode_score = 0\n",
    "            if episode % 2 == 0:\n",
    "                print(\"\\rEpisode {}/{}.\".format(episode, TOTAL_EPISODES), end=\"\")\n",
    "                sys.stdout.flush()\n",
    "                #epsilon = max(epsilon * DECAY_FACTOR, MIN)#<-- uncomment if you want to use decaying epsilon\n",
    "            state = self.env.reset()\n",
    "            self.episode_information = []\n",
    "            done = False\n",
    "            for t in itertools.count():\n",
    "                probs = self.epsilon_greedy_policy(state, epsilon)\n",
    "                action = np.random.choice(np.arange(len(probs)), p = probs)\n",
    "                state_prime, reward, done, _ = self.env.step(action)\n",
    "                episode_score += reward\n",
    "                self.episode_information.append((state, action, reward))\n",
    "                if done or t > MAX_T :break\n",
    "                state = state_prime\n",
    "            self.on_policy_returns()\n",
    "            self.MC_episode_scores.append(episode_score)\n",
    "\n",
    "    def on_policy_returns(self):\n",
    "        unique_state_action_pairs_in_episode = set([(x[STATE], x[ACTION]) for x in self.episode_information])\n",
    "        for state, action in unique_state_action_pairs_in_episode:\n",
    "            first_occurence_idx = next(idx for idx, x in enumerate(self.episode_information) if x[STATE] == state and x[ACTION] == action)\n",
    "            G = sum([x[REWARD]*(self.gamma**i) for i, x in enumerate(self.episode_information[first_occurence_idx:])])\n",
    "            self.returns_sum[(state, action)] += G\n",
    "            self.returns_count[(state, action)] += 1.0\n",
    "            self.Q[state][action] = self.returns_sum[(state, action)] / self.returns_count[(state, action)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 293417,
     "status": "ok",
     "timestamp": 1609768523862,
     "user": {
      "displayName": "Narjes Noorzad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj7tkVNhkAPpQLlGPleUdGAeLotodizEcuFCkFIkA=s64",
      "userId": "16921968874120068723"
     },
     "user_tz": -210
    },
    "id": "GH1DPu3neJ2u",
    "outputId": "71dda023-6080-4d85-bf2f-cf41a3d41727"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2000/2000."
     ]
    }
   ],
   "source": [
    "# env =  Environment.GridworldEnv() #<--uncomment for normal environment\n",
    "#env =  Modified_Environment.GridworldEnv() # <--uncomment for modified environment (bonus part)\n",
    "agent = OnPolicyMCAgent(env, gamma)\n",
    "agent.reach_island()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vb8jF2ZrFe-r"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(TOTAL_EPISODES), agent.MC_episode_scores, color = '#633974', label = '$\\epsilon$ = from $0.5$ to $0.1$')\n",
    "plt.xlabel('episodes ->')\n",
    "plt.ylabel('epsiode score ->')\n",
    "plt.title('On-policy Monte Carlo')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_VZ2r7yVd5RP"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "window_size = 50\n",
    "smoothed_score = pd.Series(agent.MC_episode_scores).rolling(window_size , min_periods = window_size).mean()\n",
    "plt.plot(smoothed_score, color = '#633974', label = '$\\epsilon$ = from $0.5$ to $0.1$')\n",
    "#plt.annotate(smoothed_score.iloc[-1], xy=(2000, -14), xytext=(2000, -14), color = '#633974',) # <--uncomment for modified environment (bonus part)\n",
    "plt.xlabel(\"epsiode ->\")\n",
    "plt.ylabel(\"epsiode score (smoothed) -> \")\n",
    "plt.title('On-policy Monte Carlo')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 1147,
     "status": "ok",
     "timestamp": 1609768558428,
     "user": {
      "displayName": "Narjes Noorzad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj7tkVNhkAPpQLlGPleUdGAeLotodizEcuFCkFIkA=s64",
      "userId": "16921968874120068723"
     },
     "user_tz": -210
    },
    "id": "1PLRSjeyIMEV"
   },
   "outputs": [],
   "source": [
    "#i wrote my reward data into a .txt file to use it later.\n",
    "\n",
    "# with open('MC_bonus_scores', 'wb') as fp:\n",
    "#     pickle.dump(agent.MC_episode_scores, fp)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMxrBYvjMXEsCUNm2XMqIdG",
   "collapsed_sections": [],
   "name": "On-policy_MonteCarlo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
